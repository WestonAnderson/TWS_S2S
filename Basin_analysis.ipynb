{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "063a8b82-7873-4e72-be2c-948b96fcf5c1",
   "metadata": {},
   "source": [
    "# Basin analysis\n",
    "Code to calculate autocorrelations and cross-correlations for data within a specific basin or set of basins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cc4680f-1842-49f6-a8e2-4f047059af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2c9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define an e-folding time function that takes an autocorrelation or cross-correlation vector as its input\n",
    "\n",
    "#the function requires the values of autocorrelation or crosscorrelation and the length of the time series used\n",
    "# to calculate those values\n",
    "\n",
    "#the function returns the e-folding value, the value that fell below e, and the degrees of freedom\n",
    "\n",
    "def e_fold(corrTS,lenTS):\n",
    "    #start from the max value in the first year\n",
    "    maxVal = np.max(corrTS[:12])\n",
    "    maxValLoc = np.argmax(corr[:12])\n",
    "    for i,val in enumerate(corrTS[maxValLoc:]):\n",
    "        if val < maxVal/np.e: #limit the values of correlation or cross-corr to the first year for max value\n",
    "            Te = i\n",
    "            val_Te = val\n",
    "            break\n",
    "    dof = (lenTS*1)/(2*Te)\n",
    "    return Te, val_Te, dof, maxVal, maxValLoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e182a5-5f15-4bc9-9ba5-1fef1a712f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gapFills = ['clim','glws2'] #gapFill as either 'clim' or 'glws2'\n",
    "\n",
    "variables = ['e_gleam_mm_mon','glws2_gwater_mm','grace_lwe_cm','grun_ens_runoff_mm_day',\n",
    "             'prec_fldas_mm_day','smroot_gleam_mm3_mm3','smsurf_gleam_mm3_mm3','lai_gimms4g_m2_m2']\n",
    "variable2s = ['e_gleam_mm_mon','glws2_gwater_mm','grace_lwe_cm','grun_ens_runoff_mm_day',\n",
    "              'prec_fldas_mm_day','smroot_gleam_mm3_mm3','smsurf_gleam_mm3_mm3','lai_gimms4g_m2_m2']\n",
    "\n",
    "basins = ['LIMPOPO','ORANGE','NILE','JUBBA (also GENALE WENZ)']\n",
    "\n",
    "bName=[];v1=[];v2=[];vcc=[];gFill=[];lens=[];\n",
    "Te=[];eVal=[];eDoF=[];sig=[];mxV=[];mxVloc=[]\n",
    "for gapFill in gapFills:\n",
    "    for basin in basins:\n",
    "        for variable in variables:\n",
    "            for variable2 in variable2s:\n",
    "                #read basin dataframe\n",
    "                path = './Basin_data/'+variable+'_'+basin+'.csv'\n",
    "                path2 = './Basin_data/'+variable2+'_'+basin+'.csv'\n",
    "                glwsPath = './Basin_data/glws2_tws_anom_mm_'+basin+'.csv'\n",
    "\n",
    "                bDF = pd.read_csv(path)\n",
    "                bDF2 = pd.read_csv(path2)\n",
    "                glwsDF = pd.read_csv(glwsPath)\n",
    "\n",
    "                #plot climatology\n",
    "                plt.figure()\n",
    "                bDF.iloc[:,1:].mean(0).plot(title='Climatology of '+variable+'\\nin '+basin+' basin')\n",
    "                plt.savefig('./Figures/Climatologies/'+variable+'_'+basin+'.png')\n",
    "                plt.close()\n",
    "\n",
    "                bDFclim = bDF.iloc[:,1:].mean(0)\n",
    "                bDFclim = bDFclim.reset_index().rename(columns={'index':'Month',0:'value'})\n",
    "                bDF2clim = bDF2.iloc[:,1:].mean(0)\n",
    "                bDF2clim = bDF2clim.reset_index().rename(columns={'index':'Month',0:'value'})\n",
    "\n",
    "                glwsDFclim = glwsDF.iloc[:,1:].mean(0)\n",
    "                glwsDFclim = glwsDFclim.reset_index().rename(columns={'index':'Month',0:'value'})\n",
    "\n",
    "                #Calculate anomalies by remove monthly climatology from each month\n",
    "                bDF.iloc[:,1:] = bDF.iloc[:,1:] - bDF.iloc[:,1:].mean(0)\n",
    "                bDF2.iloc[:,1:] = bDF2.iloc[:,1:] - bDF2.iloc[:,1:].mean(0)\n",
    "                glwsDF.iloc[:,1:] = glwsDF.iloc[:,1:] - glwsDF.iloc[:,1:].mean(0)\n",
    "                #reshape the data\n",
    "                bDF = bDF.melt(id_vars='Year',var_name='Month')\n",
    "                bDF2 = bDF2.melt(id_vars='Year',var_name='Month')\n",
    "                glwsDF = glwsDF.melt(id_vars='Year',var_name='Month')\n",
    "                #create a datetime index\n",
    "                dtInd = pd.to_datetime(bDF.Year.astype(int).astype(str) + bDF['Month'], format='%Y%b')\n",
    "                bDF['date'] = dtInd\n",
    "                dtInd2 = pd.to_datetime(bDF2.Year.astype(int).astype(str) + bDF2['Month'], format='%Y%b')\n",
    "                bDF2['date'] = dtInd2\n",
    "                dtIndglws = pd.to_datetime(glwsDF.Year.astype(int).astype(str) + glwsDF['Month'], format='%Y%b')\n",
    "                glwsDF['date'] = dtIndglws          \n",
    "                bDF=bDF.set_index('date')\n",
    "                bDF2=bDF2.set_index('date')\n",
    "                glwsDF=glwsDF.set_index('date')\n",
    "\n",
    "                if (variable=='grun_ens_runoff_mm_day')&(variable2=='grun_ens_runoff_mm_day'):\n",
    "                    dtInd = dtInd[(dtInd.dt.year>1981)] #limit to satellite era to be more similar to other vars   \n",
    "                    dtInd2 = dtInd2[(dtInd2.dt.year>1981)]\n",
    "                if variable=='grace_lwe_cm':\n",
    "                    if gapFill == 'clim':\n",
    "                        #replace missing values with climatology (which is = 0 in anomaly space)\n",
    "                        bDF.loc[np.isnan(bDF['value']),'value'] = 0 \n",
    "                    elif gapFill == 'glws2':\n",
    "                        dt_t = np.isin(dtInd,dtIndglws)\n",
    "                        bDF.loc[(np.isnan(bDF['value']))&(list(dt_t)),'value'] = \\\n",
    "                            glwsDF.loc[(np.isnan(bDF['value']))&(list(dt_t)),'value'].values/10 #convert to cm\n",
    "                        dtInd = dtInd[(dtInd.dt.year>2002)]\n",
    "                    else:\n",
    "                        print('not a valid gap fill option')\n",
    "                        break\n",
    "                    dtInd = dtInd[(dtInd.dt.year<=2022)]\n",
    "                if variable2=='grace_lwe_cm':\n",
    "                    if gapFill == 'clim':\n",
    "                        #replace missing values with climatology (which is = 0 in anomaly space)\n",
    "                        bDF2.loc[np.isnan(bDF2['value']),'value'] = 0\n",
    "                    elif gapFill == 'glws2':\n",
    "                        dt_t = np.isin(dtInd2,dtIndglws)\n",
    "                        bDF2.loc[(np.isnan(bDF2['value']))&(list(dt_t)),'value'] = \\\n",
    "                            glwsDF.loc[(np.isnan(bDF2['value']))&(list(dt_t)),'value'].values/10 #convert to cm\n",
    "                        dtInd2 = dtInd2[(dtInd2.dt.year>2002)]#glws v2 not available in 2002\n",
    "                    else:\n",
    "                        print('not a valid gap fill option')\n",
    "                        break\n",
    "                    dtInd = dtInd[(dtInd.dt.year<=2022)]\n",
    "\n",
    "                #choose only values that exist in both datasets to calculate the cross correlation\n",
    "                dts = set(dtInd).intersection(dtInd2)\n",
    "                bDF=bDF.loc[list(dts)]\n",
    "                bDF2=bDF2.loc[list(dts)]\n",
    "\n",
    "                #reorder the data chronologically\n",
    "                bDF = bDF.sort_values(by='date')\n",
    "                bDF2 = bDF2.sort_values(by='date')\n",
    "\n",
    "                #Calculate the autocorrelation\n",
    "                if variable == variable2:\n",
    "                    anoms = bDF.value.values\n",
    "                    anoms = anoms-np.nanmean(anoms)\n",
    "                    std = np.std(anoms)\n",
    "                    corr = sm.tsa.stattools.ccf(anoms/std,anoms/std,adjusted=True,fft=False)\n",
    "                    plt.figure()\n",
    "                    plt.plot(corr[:9])\n",
    "                    plt.title(variable+' autocorrelation out to 9 months')\n",
    "                    plt.savefig('./Figures/crosscorrelations_individual_vars/'+variable+'_'+basin+'.png')\n",
    "                    plt.close()\n",
    "                else:\n",
    "                    anoms = bDF.value.values\n",
    "                    anoms2 = bDF2.value.values\n",
    "                    anoms = anoms-np.nanmean(anoms)\n",
    "                    anoms2 = anoms2-np.nanmean(anoms2)\n",
    "                    std = np.std(anoms)\n",
    "                    std2 = np.std(anoms2)\n",
    "                    corr = sm.tsa.stattools.ccf(anoms/std,anoms2/std2,adjusted=True,fft=False)\n",
    "                    plt.figure()\n",
    "                    plt.plot(corr[:9])\n",
    "                    plt.title(variable+' lags \\n'+variable2+'\\ncross-correlation out to 9 months')\n",
    "                    plt.savefig('./Figures/crosscorrelations_individual_vars/'+variable+'_'+variable2+'_'+basin+'.png')\n",
    "                    plt.close()\n",
    "                \n",
    "                sig90 = scipy.stats.norm.ppf((1 + 0.90)/2)/np.sqrt(len(anoms))\n",
    "                #sig90 = scipy.stats.norm.ppf(0.90, loc=np.mean(corr[:48]), scale=np.std(corr[:48]))\n",
    "                \n",
    "                Te_t,eVal_t,eDoF_t, mxV_t, mxVloc_t = e_fold(corr,len(anoms))\n",
    "                \n",
    "                sig = np.append(sig,1*(sig90<=corr[:9]),0)\n",
    "                vcc = np.append(vcc,corr[:9],0)\n",
    "                v1 = np.append(v1,np.repeat(variable,9),0)\n",
    "                v2 = np.append(v2,np.repeat(variable2,9),0)\n",
    "                bName = np.append(bName,np.repeat(basin,9),0)\n",
    "                gFill = np.append(gFill,np.repeat(gapFill,9),0)\n",
    "                lens = np.append(lens,np.repeat(len(anoms),9),0)\n",
    "                Te = np.append(Te, np.repeat(Te_t,9),0)\n",
    "                eVal = np.append(eVal, np.repeat(eVal_t,9),0)\n",
    "                eDoF = np.append(eDoF, np.repeat(eDoF_t,9),0)\n",
    "                mxV = np.append(mxV, np.repeat(mxV_t,9),0)\n",
    "                mxVloc = np.append(mxVloc, np.repeat(mxVloc_t,9),0)\n",
    "                \n",
    "df =pd.DataFrame(data={'basin':bName,'var1':v1,'var2':v2,'cross_corr':vcc,'gapFill':gFill,\n",
    "                       'n':lens,'Te':Te,'eDoF':eDoF,'90pctSig':sig,'maxCorr':mxV,'maxCorrLag',mxVloc})\n",
    "path = './crosscorr_dfs/basin_cc.pkl'\n",
    "df.to_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3804e3d-b0d6-4581-be12-dcd635704ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pk/_ym78shs7tx06w00zbcwxwgc0000gp/T/ipykernel_62390/997312057.py:21: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n"
     ]
    }
   ],
   "source": [
    "#First calculate the e-folding time of the cross-correlations \n",
    "#then write it to a new array and plot the cross-correlations\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "colors = {\n",
    "'e_gleam_mm_mon':'limegreen',\n",
    "'glws2_gwater_mm':'navy',\n",
    "'grace_lwe_cm':'red',\n",
    "'grun_ens_runoff_mm_day':'blue',\n",
    "'prec_fldas_mm_day':'cornflowerblue',\n",
    "'smroot_gleam_mm3_mm3':'saddlebrown',\n",
    "'smsurf_gleam_mm3_mm3':'peru',\n",
    "'lai_gimms4g_m2_m2':'green'\n",
    "}\n",
    "\n",
    "Te=[],\n",
    "for igapFill in gapFills:\n",
    "    for basin in basins:\n",
    "        for variable in variables:\n",
    "            plt.figure()\n",
    "            for variable2 in variable2s:\n",
    "                if variable==variable2:continue\n",
    "                corrTS = df[(df.gapFill==igapFill)&(df.basin==basin)&(df.var1==variable)&(df.var2==variable2)].cross_corr.values\n",
    "                sigCorr = df.loc[(df.gapFill==igapFill)&(df.basin==basin)&(df.var1==variable)&(df.var2==variable2),'90pctSig'].values\n",
    "                plt.plot(corrTS,label=str(variable2),color=colors[variable2])\n",
    "                if np.sum(sigCorr>0):\n",
    "                    plt.scatter(np.where(sigCorr==1)[0],corrTS[sigCorr==1],color=colors[variable2])\n",
    "            plt.legend()\n",
    "            plt.title(basin+'\\n'+variable+' lags [X]')\n",
    "            plt.savefig('./Figures/crosscorrelations_all_vars/'+variable+'_allVars_'+basin+'_'+igapFill+'.png')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db2967a8-7e74-4b70-bcae-cd9e2c0806c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "basins = ['LIMPOPO','ORANGE','NILE','JUBBA (also GENALE WENZ)']\n",
    "\n",
    "colors = {\n",
    "'JUBBA (also GENALE WENZ)':'red',\n",
    "'NILE':'cornflowerblue',\n",
    "'ORANGE':'peru',\n",
    "'LIMPOPO':'green'\n",
    "}\n",
    "\n",
    "for igapFill in gapFills:\n",
    "    for variable in variables:\n",
    "        plt.figure()\n",
    "        for basin in basins:\n",
    "            corrTS = df[(df.gapFill==igapFill)&(df.basin==basin)&(df.var1==variable)&(df.var2==variable)].cross_corr.values\n",
    "            sigCorr = df.loc[(df.gapFill==igapFill)&(df.basin==basin)&(df.var1==variable)&(df.var2==variable),'90pctSig'].values\n",
    "            plt.plot(corrTS,label=str(basin),color=colors[basin])\n",
    "            if np.sum(sigCorr>0):\n",
    "                    plt.scatter(np.where(sigCorr==1)[0],corrTS[sigCorr==1],color=colors[basin])\n",
    "            plt.legend()\n",
    "            plt.title(variable+' autocorrelation')\n",
    "            plt.savefig('./Figures/autocorrelations_all_basins/'+variable+'_'+igapFill+'_allbasins.png')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dacc8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for igapFill in gapFills:\n",
    "    for variable in variables:\n",
    "        plt.figure()\n",
    "        eFold = df.loc[(df.gapFill==igapFill)&(df.var1==variable)&(df.var2==variable),['basin','Te']]\n",
    "        eFold.drop_duplicates().plot.bar(x='basin',y='Te')\n",
    "        plt.title(variable+' autocorrelation e-folding time (months)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('./Figures/e_Folding/eFolding_autocorrelation_'+variable+'_'+igapFill+'_allbasins.png')      \n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02541839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
